@inproceedings{angeline_competitive_1993,
	address = {Pittsburgh, PA},
	title = {Competitive {Environments} {Evolve} {Better} {Solutions} for {Complex} {Tasks}},
	isbn = {978-0-8058-0426-3},
	shorttitle = {{ICGA} 1},
	abstract = {In the typical genetic algorithm experiment, the fitness function is constructed to be independent of the contents of the population to provide a consistent objective measure. Such objectivity entails significant knowledge about the environment which suggests either the problem has previously been solved or other non-evolutionary techniques may be more efficient. Furthermore, for many complex tasks an independent fitness function is either impractical or impossible to provide. In this paper, we demonstrate that competitive fitness functions, i.e. fitness functions that are dependent on the constituents of the population, can provide a more robust training environment than independent fitness functions. We describe three differing methods for competitive fitness, and discuss their respective advantages.},
	booktitle = {Proceedings {Of} {The} {First} {International} {Conference} {On} {Genetic} {Algorithms} {And} {Their} {Applications}},
	publisher = {Psychology Press},
	author = {Angeline, Peter J. and Pollack, Jordan B.},
	editor = {Grefenstette, John J.},
	month = jun,
	year = {1993},
	keywords = {adversary, coevolution, competition, cooperative, evolution, games, genetic algorithm, Genetic programming},
	pages = {1--7},
	file = {Angeline and Pollack - 1993 - Competitive Environments Evolve Better Solutions f.pdf:/Users/cwr/Zotero/storage/Z8P7CATV/Angeline and Pollack - 1993 - Competitive Environments Evolve Better Solutions f.pdf:application/pdf;Citeseer - Snapshot:/Users/cwr/Zotero/storage/DCGBXU6M/summary.html:text/html},
}

@article{bi_genetic_2022,
    title={Genetic Programming-Based Evolutionary Deep Learning for Data-Efficient Image Classification},
    author={Bi, Ying and Xue, Bing and Zhang, Mengjie},
    journal={IEEE Transactions on Evolutionary Computation},
    year={2022},
    doi={10.1109/TEVC.2022.3214503},
    pages={15},
    volume = {0},
    number = {0},
    publisher={IEEE}
}

@incollection{chastain_multiplicative_2013,
	address = {New York, NY, USA},
	title = {Multiplicative updates in coordination games and the theory of evolution},
	isbn = {978-1-4503-1859-4},
	url = {https://doi.org/10.1145/2422436.2422444},
	abstract = {In this paper we point out a new and unexpected connection between three fields: Evolution Theory, Game Theory, and Algorithms. In particular, we study the standard equations of population genetics for Evolution, in the presence of recombination (sex), focusing on the important special case of weak selection [1,2] in which all fitness values are assumed to be close to one another. Weak selection is the mathematical regime capturing the widely accepted Neutral Theory proposed by Kimura in the 1970s [3], hypothesizing that evolution proceeds for the most part not by substantial increases in fitness but by essentially random drift. We show that in this regime evolution through natural selection and sex is tantamount to a game played through the multiplicative weight updates game dynamics [4]. The players of the game are the genes (genetic loci), the strategies available to each player are the alleles of the gene, and the probabilities whereby a player plays a strategy is the strategy's frequency in the population. The utility to each player/gene of each strategy profile is the fitness of the corresponding genotype (organism). That is, the game is a coordination game between genes, in which the players' interests are perfectly aligned. Importantly, the utility maximized in this game, as well as the amount by which each allele is boosted, is precisely the allele's mixability, or average fitness, a quantity recently proposed in [5] as a novel concept that is crucial in understanding natural selection under sex, thus providing a rigorous demonstration of that insight. We also establish a result regarding the maintenance of genetic diversity (multiplicity of alleles per gene). We prove that the equilibria in two-person coordination games are likely to have large supports, and thus genetic diversity need not suffer much at equilibrium. Establishing large supports involves answering through a novel technique the following question: what is the probability that for a random square matrix \$A\$ (with entries drawn independently from smooth distributions that are symmetric around zero) both systems Ax=1 and ATy=1 have positive solutions? The proof is through a simple potential function argument. Both the question and the technique may be of broader interest. It has often seemed astonishing --- even to experienced students of Evolution, Darwin included --- that the crude mechanism of natural selection is responsible for producing the dazzling variety of Life around us. The present mathematical connection of Evolution with the multiplicative weight updates algorithm --- a technique that has surprised our field time and again with its fantastic effectiveness and versatility --- may carry some explanatory force in this regard.},
	urldate = {2022-11-05},
	booktitle = {Proceedings of the 4th conference on {Innovations} in {Theoretical} {Computer} {Science}},
	publisher = {Association for Computing Machinery},
	author = {Chastain, Erick and Livnat, Adi and Papadimitriou, Christos and Vazirani, Umesh},
	month = jan,
	year = {2013},
	keywords = {algorithmic game theory, multiplicative weight updates, theory of evolution},
	pages = {57--58},
	file = {Chastain et al. - 2013 - Multiplicative updates in coordination games and t.pdf:/Users/cwr/Zotero/storage/N882C76B/Chastain et al. - 2013 - Multiplicative updates in coordination games and t.pdf:application/pdf},
}

@article{chen_boundary-guided_2022,
	title = {Boundary-guided network for camouflaged object detection},
	volume = {248},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705122004294},
	doi = {https://doi.org/10.1016/j.knosys.2022.108901},
	abstract = {Compared with the traditional object segmentation/detection, camouflaged object detection is much more difficult due to the indefinable boundaries and high intrinsic similarities between the camouflaged regions and the background. Although various algorithms have been proposed to solve the issue, these methods still suffer from coarse boundaries and are not competent to identify the camouflaged objects from the background in complex scenarios. In this paper, we propose a novel boundary-guided network to address this challenging problem in a coarse-to-fine manner. Specifically, we design a locating module to infer the initial location of the camouflaged objects by exploiting local detailed cues and global contextual information. Moreover, a boundary-guided fusion module is proposed to explore the complementary relationship between the camouflaged regions and their boundaries. By leveraging the boundary feature, we can not only generate prediction maps with sharper boundaries but also effectively eliminate background noises. Equipped with the two key modules, our BgNet is capable of segmenting camouflaged regions accurately and quickly. Extensive experimental results on four widely used benchmark datasets demonstrate that the proposed BgNet runs at a real-time speed (36 FPS) on a single NVIDIA Titan XP GPU and outperforms 17 state-of-the-art competing algorithms in terms of six standard evaluation metrics. Source code will be publicly available at https://github.com/clelouch/BgNet upon paper acceptance.},
	journal = {Knowledge-Based Systems},
	author = {Chen, Tianyou and Xiao, Jin and Hu, Xiaoguang and Zhang, Guofeng and Wang, Shaojie},
	year = {2022},
	keywords = {Boundary guidance, Camouflage object detection, Coarse-to-fine refinement, Convolutional neural network},
	pages = {108901},
}

@misc{chollet_keras_2015,
    title={Keras},
    author={Chollet, Fran\c{c}ois and others},
    year={2015},
    howpublished={\url{https://keras.io}},
}

@article{chu_camo_image_2010,
    author = {Chu, Hung-Kuo and Hsu, Wei-Hsin and Mitra, Niloy J. and Cohen-Or, Daniel and Wong, Tien-Tsin and Lee, Tong-Yee},
    title = {Camouflage Images},
    year = {2010},
    issue_date = {July 2010},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {29},
    number = {4},
    issn = {0730-0301},
    url = {https://doi.org/10.1145/1778765.1778788},
    doi = {10.1145/1778765.1778788},
    abstract = {Camouflage images contain one or more hidden figures that remain imperceptible or unnoticed for a while. In one possible explanation, the ability to delay the perception of the hidden figures is attributed to the theory that human perception works in two main phases: feature search and conjunction search. Effective camouflage images make feature based recognition difficult, and thus force the recognition process to employ conjunction search, which takes considerable effort and time. In this paper, we present a technique for creating camouflage images. To foil the feature search, we remove the original subtle texture details of the hidden figures and replace them by that of the surrounding apparent image. To leave an appropriate degree of clues for the conjunction search, we compute and assign new tones to regions in the embedded figures by performing an optimization between two conflicting terms, which we call immersion and standout, corresponding to hiding and leaving clues, respectively. We show a large number of camouflage images generated by our technique, with or without user guidance. We have tested the quality of the images in an extensive user study, showing a good control of the difficulty levels.},
    journal = {ACM Trans. Graph.},
    month = {jul},
    articleno = {51},
    numpages = {8}
}

@inproceedings{cramer_representation_1985,
	address = {Carnegie-Mellon University, Pittsburgh, PA, USA},
	title = {A {Representation} for the {Adaptive} {Generation} of {Simple} {Sequential} {Programs}},
	shorttitle = {{ICGA} 1985},
	abstract = {An adaptive system for generating short sequential computer functions is described. The created functions are written in the simple "number-string" language JB, and in TB, a modified version of JB with a tree-like structure. These languages have the feature that they can be used to represent well-formed, useful computer programs while still being amenable to suitably defined genetic operators. The system is used to produce two-input, single-output multiplication functions that are concise and well-defined. Future work, dealing with extensions to more complicated functions and generalizations of the techniques, is also discussed.},
	booktitle = {Proceedings of an {International} {Conference} {On} {Genetic} {Algorithms} {And} {Their} {Applications}},
	publisher = {Lawrence Erlbaum Associates},
	author = {Cramer, Nichael Lynn},
	month = jul,
	year = {1985},
	keywords = {algorithm, evolution, ga, Genetic programming, gp, history, induction, optimization, programming},
	pages = {183--187},
	file = {Cramer - 1985 - A Representation for the Adaptive Generation of Si.pdf:/Users/cwr/Zotero/storage/DNLKQ4TB/Cramer - 1985 - A Representation for the Adaptive Generation of Si.pdf:application/pdf},
}

@article{de_alcantara_viana_predator_2022,
	title = {Predator responses to prey camouflage strategies: a meta-analysis},
	volume = {289},
	shorttitle = {Predator responses to prey camouflage strategies},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rspb.2022.0980},
	doi = {10.1098/rspb.2022.0980},
	abstract = {Although numerous studies about camouflage have been conducted in the last few decades, there is still a significant gap in our knowledge about the magnitude of protective value of different camouflage strategies in prey detection and survival. Furthermore, the functional significance of several camouflage strategies remains controversial. Here we carried out a comprehensive meta-analysis including comparisons of different camouflage strategies as well as predator and prey types, considering two response variables: mean predator search time (ST) (63 studies) and predator attack rate (AR) of camouflaged prey (28 studies). Overall, camouflage increased the predator ST by 62.56\% and decreased the AR of prey by 27.34\%. Masquerade was the camouflage strategy that most increased predator ST (295.43\%). Background matching and disruptive coloration did not differ from each other. Motion camouflage did not increase ST but decreases AR on prey. We found no evidence that eyespot increases ST and decreases AR by predators. The different types of predators did not differ from each other, but caterpillars were the type of prey that most influenced the magnitude of camouflage's effect. We highlight the potential evolutionary mechanisms that led camouflage to be a highly effective anti-predatory adaptation, as well as potential discrepancies or redundancies among strategies, predator and prey types.},
	number = {1982},
	urldate = {2023-01-09},
	journal = {Proceedings of the Royal Society B: Biological Sciences},
	author = {de Alcantara Viana, João Vitor and Vieira, Camila and Duarte, Rafael Campos and Romero, Gustavo Quevedo},
	month = sep,
	year = {2022},
	note = {Publisher: Royal Society},
	keywords = {behavior, cocish, evolution, predator, prey, detection, survey, predator-prey interactions, disruptive coloration, antipredator behaviour, background-matching, concealment, masquerade},
	pages = {20220980},
	file = {Full Text PDF:/Users/cwr/Zotero/storage/92ACYCMY/de Alcantara Viana et al. - 2022 - Predator responses to prey camouflage strategies .pdf:application/pdf},
}

@book{dawkins_blind_1986,
	address = {New York, NY, USA},
	title = {The {Blind} {Watchmaker}},
	isbn = {0-393-31570-3},
	url = {https://wwnorton.com/books/The-Blind-Watchmaker/},
	abstract = {One of the most famous arguments of the creationist theory of the universe is the eighteenth-century theologian William Paley's: Just as a watch is too complicated and too functional to have sprung into existence by accident, so too must all living things, with their far greater complexity, be purposefully designed. But as Richard Dawkins, professor of zoology at Oxford University, demonstrates in this brilliant and eloquent riposte to the Argument from Design, the analogy is false. Natural selection, the unconscious, automatic, blind yet essentially non-random process that Darwin discovered, has no purpose in mind. If it can be said to play the role of watchmaker in nature, it is the blind watchmaker. Patiently and lucidly, Dr. Dawkins - in this book which has been acclaimed as perhaps the most influential work on evolution written in this century - identifies those aspects of the theory which people find hard to believe and removes the barrier to credibility one by one.},
	publisher = {W. W. Norton \& Company, Inc.},
	author = {Dawkins, Richard},
	month = sep,
	year = {1986},
	keywords = {evolution, humanfitnessfunction},
}

@article{de_gomensoro_malheiros_leopard_2020,
	title = {The leopard never changes its spots: realistic pigmentation pattern formation by coupling tissue growth with reaction-diffusion},
	volume = {39},
	issn = {0730-0301},
	shorttitle = {The leopard never changes its spots},
	url = {https://doi.org/10.1145/3386569.3392478},
	doi = {10.1145/3386569.3392478},
	abstract = {Previous research in pattern formation using reaction-diffusion mostly focused on static domains, either for computational simplicity or mathematical tractability. In this work, we have explored the expressiveness of combining simple mechanisms as a possible explanation for pigmentation pattern formation, where tissue growth plays a crucial role. Our motivation is not only to realistically reproduce natural patterns but also to get insights into the underlying biological processes. Therefore, we present a novel approach to generate realistic animal skin patterns. First, we describe the approximation of tissue growth by a series of discrete matrix expansion operations. Then, we combine it with an adaptation of Turing's non-linear reaction-diffusion model, which enforces upper and lower bounds to the concentrations of the involved chemical reagents. We also propose the addition of a single-reagent continuous autocatalytic reaction, called reinforcement, to provide a mechanism to maintain an already established pattern during growth. By careful adjustment of the parameters and the sequencing of operations, we closely match the appearance of a few real species. In particular, we reproduce in detail the distinctive features of the leopard skin, also providing a hypothesis for the simultaneous productions of the most common melanin types, eumelanin and pheomelanin.},
	number = {4},
	urldate = {2022-10-23},
	journal = {ACM Transactions on Graphics},
	author = {De Gomensoro Malheiros, Marcelo and Fensterseifer, Henrique and Walter, Marcelo},
	month = jul,
	year = {2020},
	keywords = {natural phenomena, pattern formation, reaction-diffusion, texturing, turing model},
	pages = {63:63:1--63:62:14},
}


@misc{gao_nerf_2022,
	title = {{NeRF}: {Neural} {Radiance} {Field} in {3D} {Vision}, {A} {Comprehensive} {Review}},
	shorttitle = {{NeRF}},
	url = {http://arxiv.org/abs/2210.00379},
	doi = {10.48550/arXiv.2210.00379},
	abstract = {Neural Radiance Field (NeRF), a new novel view synthesis with implicit scene representation has taken the field of Computer Vision by storm. As a novel view synthesis and 3D reconstruction method, NeRF models find applications in robotics, urban mapping, autonomous navigation, virtual reality/augmented reality, and more. Since the original paper by Mildenhall et al., more than 250 preprints were published, with more than 100 eventually being accepted in tier one Computer Vision Conferences. Given NeRF popularity and the current interest in this research area, we believe it necessary to compile a comprehensive survey of NeRF papers from the past two years, which we organized into both architecture, and application based taxonomies. We also provide an introduction to the theory of NeRF based novel view synthesis, and a benchmark comparison of the performance and speed of key NeRF models. By creating this survey, we hope to introduce new researchers to NeRF, provide a helpful reference for influential works in this field, as well as motivate future research directions with our discussion section.},
	urldate = {2022-11-19},
	publisher = {arXiv},
	author = {Gao, Kyle and Gao, Yina and He, Hongjie and Lu, Denning and Xu, Linlin and Li, Jonathan},
	month = nov,
	year = {2022},
	note = {arXiv:2210.00379 [cs]},
	keywords = {3d, Computer Science - Computer Vision and Pattern Recognition, deep neural networks, image based rendering, nerf, survey, vision},
	file = {arXiv Fulltext PDF:/Users/cwr/Zotero/storage/9ZL5759C/Gao et al. - 2022 - NeRF Neural Radiance Field in 3D Vision, A Compre.pdf:application/pdf;arXiv.org Snapshot:/Users/cwr/Zotero/storage/EUHBEERH/2210.html:text/html},
}

@book{glassner_deep_2021,
	address = {San Francisco, CA},
	title = {Deep {Learning}: {A} {Visual} {Approach}},
	isbn = {978-1-71850-072-3},
	url = {https://nostarch.com/deep-learning-visual-approach},
	publisher = {No Starch Press},
	author = {Glassner, Andrew},
	year = {2021},
	keywords = {classification, deep\_learning, deeplearning, gan, learning, machinelearning, neural\_nets, optimization, regression, statistics, tutorial, visualization},
}

@misc{goodfellow_gan_2014,
    doi = {10.48550/ARXIV.1406.2661},
    url = {https://arxiv.org/abs/1406.2661},
    author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    abstract = {Generative adversarial networks are a kind of artificial intelligence algorithm designed to solve the generative modeling problem. The goal of a generative model is to study a collection of training examples and learn the probability distribution that generated them. Generative Adversarial Networks (GANs) are then able to generate more examples from the estimated probability distribution. Generative models based on deep learning are common, but GANs are among the most successful generative models (especially in terms of their ability to generate realistic high-resolution images). GANs have been successfully applied to a wide variety of tasks (mostly in research settings) but continue to present unique challenges and research opportunities because they are based on game theory while most other approaches to generative modeling are based on optimization.},
    keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {Generative Adversarial Networks},
    publisher = {arXiv},
    year = {2014},
    copyright = {arXiv.org perpetual, non-exclusive license},
    note = {Republished in 2020 in CACM: https://doi.org/10.1145/3422622}
}

@article{Guerrero_MatFormer_2022,
    author = {Guerrero, Paul and Ha\v{s}an, Milo\v{s} and Sunkavalli, Kalyan and M\v{e}ch, Radom\'{\i}r and Boubekeur, Tamy and Mitra, Niloy J.},
    title = {MatFormer: A Generative Model for Procedural Materials},
    year = {2022},
    issue_date = {July 2022},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {41},
    number = {4},
    issn = {0730-0301},
    url = {https://doi.org/10.1145/3528223.3530173},
    doi = {10.1145/3528223.3530173},
    abstract = {Procedural material graphs are a compact, parameteric, and resolution-independent representation that are a popular choice for material authoring. However, designing procedural materials requires significant expertise and publicly accessible libraries contain only a few thousand such graphs. We present MatFormer, a generative model that can produce a diverse set of high-quality procedural materials with complex spatial patterns and appearance. While procedural materials can be modeled as directed (operation) graphs, they contain arbitrary numbers of heterogeneous nodes with unstructured, often long-range node connections, and functional constraints on node parameters and connections. MatFormer addresses these challenges with a multi-stage transformer-based model that sequentially generates nodes, node parameters, and edges, while ensuring the semantic validity of the graph. In addition to generation, MatFormer can be used for the auto-completion and exploration of partial material graphs. We qualitatively and quantitatively demonstrate that our method outperforms alternative approaches, in both generated graph and material quality.},
    journal = {ACM Trans. Graph.},
    month = {jul},
    articleno = {46},
    numpages = {12},
    keywords = {transformers, node graphs, procedural materials, generative models}
    }

@misc{guo_ganmouflage_2022,
	title = {GANmouflage: 3D Object Nondetection with Texture Fields},
	shorttitle = {{GANmouflage}},
	url = {http://arxiv.org/abs/2201.07202},
	abstract = {We propose a method that learns to camouflage 3D objects within scenes. Given an object's shape and a distribution of viewpoints from which it will be seen, we estimate a texture that will make it difficult to detect. Successfully solving this task requires a model that can accurately reproduce textures from the scene, while simultaneously dealing with the highly conflicting constraints imposed by each viewpoint. We address these challenges with a model based on texture fields and adversarial learning. Our model learns to camouflage a variety of object shapes from randomly sampled locations and viewpoints within the input scene, and is the first to address the problem of hiding complex object shapes. Using a human visual search study, we find that our estimated textures conceal objects significantly better than previous methods. Project site: https://rrrrrguo.github.io/ganmouflage/},
	urldate = {2022-01-23},
	journal = {arXiv:2201.07202 [cs]},
	author = {Guo, Rui and Collins, Jasmine and de Lima, Oscar and Owens, Andrew},
    month = {jan},
	year = {2022},
	note = {arXiv: 2201.07202},
	keywords = {camouflage, cocish, 3d, texture\_synthesis, human, detection, Computer Science - Computer Vision and Pattern Recognition, anti\_camouflage, multi\_view},
	file = {arXiv Fulltext PDF:/Users/cwr/Zotero/storage/VKQU27CT/Guo et al. - 2022 - GANmouflage 3D Object Nondetection with Texture F.pdf:application/pdf;arXiv.org Snapshot:/Users/cwr/Zotero/storage/VPPJU2P2/2201.html:text/html},
    numpages = {16},
    eprinttype = {arXiv},
    eprint={2201.07202},
}

@article{hancock_camoevo_2022,
    author = {Hancock, George R. A. and Troscianko, Jolyon},
    title = {CamoEvo: An open access toolbox for artificial camouflage evolution experiments},
    journal = {Evolution},
    volume = {76},
    number = {5},
    pages = {870-882},
    keywords = {CamoEvo, camouflage, evolution, genetic algorithms, optimization, selection},
    doi = {https://doi.org/10.1111/evo.14476},
    abstract = {Abstract Camouflage research has long shaped our understanding of evolution by natural selection, and elucidating the mechanisms by which camouflage operates remains a key question in visual ecology. However, the vast diversity of color patterns found in animals and their backgrounds, combined with the scope for complex interactions with receiver vision, presents a fundamental challenge for investigating optimal camouflage strategies. Genetic algorithms (GAs) have provided a potential method for accounting for these interactions, but with limited accessibility. Here, we present CamoEvo, an open-access toolbox for investigating camouflage pattern optimization by using tailored GAs, animal and egg maculation theory, and artificial predation experiments. This system allows for camouflage evolution within the span of just 10–30 generations (∼1–2 min per generation), producing patterns that are both significantly harder to detect and that are optimized to their background. CamoEvo was built in ImageJ to allow for integration with an array of existing open access camouflage analysis tools. We provide guides for editing and adjusting the predation experiment and GA as well as an example experiment. The speed and flexibility of this toolbox makes it adaptable for a wide range of computer-based phenotype optimization experiments.},
    year = {2022}
}

@inproceedings{harrington_coevolution_2014,
	author = {Harrington, Kyle I. and Freeman, Jesse and Pollack, Jordan},
    title = "{Coevolution in Hide and Seek: Camouflage and Vision}",
    booktitle = {ALIFE 14: The Fourteenth International Conference on the Synthesis and Simulation of Living Systems},
    address = {New York City, NY, USA},
    pages = {25-32},
    year = {2014},
    month = {07},
    publisher = {MIT Press},
    url = {https://direct.mit.edu/isal/proceedings/alife2014/25/98754},
}

@article{kimura_evolutionary_1968,
	title = {Evolutionary rate at the molecular level.},
	volume = {217},
	issn = {00280836},
	url = {http://coleoguy.github.io/reading.group/kimura.pdf},
	abstract = {Calculating the rate of evolution in terms of nucleotide substitutions seems to give a value so high that many of the mutations involved must be neutral ones.},
	number = {129},
	journal = {Nature insight : aids.},
	author = {Kimura, Motoo},
	month = jan,
	year = {1968},
	pages = {624--626},
	publisher = {Nature Publishing},
	address = {London.},
}

@book{koza_genetic_1992,
	address = {Cambridge, Mass.},
	edition = {1},
	title = {Genetic {Programming}: {On} the {Programming} of {Computers} by {Means} of {Natural} {Selection} ({Complex} {Adaptive} {Systems})},
	isbn = {0-262-11170-5},
	url = {https://mitpress.mit.edu/9780262527910/genetic-programming/},
	publisher = {MIT Press, A Bradford Book},
	author = {Koza, John R.},
	month = dec,
	year = {1992},
	keywords = {evolution, gp},
}

@inbook{latham_form_1989,
    author = {Latham, William},
    title = {Form Synth: The Rule-Based Evolution of Complex Forms from Geometric Primitives},
    year = {1989},
    isbn = {0387968962},
    publisher = {Springer-Verlag},
    address = {Berlin, Heidelberg},
    booktitle = {Computers in Art, Design and Animation},
    pages = {80–108},
    numpages = {29}
    }

@article{livnat_sex_2016,
	title = {Sex {As} an {Algorithm}: {The} {Theory} of {Evolution} {Under} the {Lens} of {Computation}},
	volume = {59},
	issn = {0001-0782},
	url = {http://dx.doi.org/10.1145/2934662},
	doi = {10.1145/2934662},
	abstract = {Looking at the mysteries of evolution from a computer science point of view yields some unexpected insights.},
	number = {11},
	journal = {Commun. ACM},
	author = {Livnat, Adi and Papadimitriou, Christos},
	month = oct,
	year = {2016},
	keywords = {simulation, cocish, evolution, algorithm, optimization, genetics, computation, drift, pac, theory, weak\_selection},
	pages = {84--93},
	file = {Livnat and Papadimitriou - 2016 - Sex As an Algorithm The Theory of Evolution Under.pdf:/Users/cwr/Zotero/storage/F747KDHT/Livnat and Papadimitriou - 2016 - Sex As an Algorithm The Theory of Evolution Under.pdf:application/pdf},
}

@misc{lv_cod_2022,
    doi = {10.48550/ARXIV.2205.11333},
    url = {https://arxiv.org/abs/2205.11333},
    author = {Lv, Yunqiu and Zhang, Jing and Dai, Yuchao and Li, Aixuan and Barnes, Nick and Fan, Deng-Ping},
    keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
    title = {Towards Deeper Understanding of Camouflaged Object Detection},
    publisher = {arXiv},
    year = {2022},
    copyright = {arXiv.org perpetual, non-exclusive license}
}

@article{Mckay_2010,
    author = {Mckay, Robert I. and Hoai, Nguyen Xuan and Whigham, Peter Alexander and Shan, Yin and O'Neill, Michael},
    title = {Grammar-Based Genetic Programming: A Survey},
    year = {2010},
    issue_date = {September 2010},
    publisher = {Kluwer Academic Publishers},
    address = {USA},
    volume = {11},
    number = {3–4},
    issn = {1389-2576},
    url = {https://doi.org/10.1007/s10710-010-9109-y},
    doi = {10.1007/s10710-010-9109-y},
    abstract = {Grammar formalisms are one of the key representation structures in Computer Science. So it is not surprising that they have also become important as a method for formalizing constraints in Genetic Programming (GP). Practical grammar-based GP systems first appeared in the mid 1990s, and have subsequently become an important strand in GP research and applications. We trace their subsequent rise, surveying the various grammar-based formalisms that have been used in GP and discussing the contributions they have made to the progress of GP. We illustrate these contributions with a range of applications of grammar-based GP, showing how grammar formalisms contributed to the solutions of these problems. We briefly discuss the likely future development of grammar-based GP systems, and conclude with a brief summary of the field.},
    journal = {Genetic Programming and Evolvable Machines},
    month = {sep},
    pages = {365–396},
    numpages = {32},
    keywords = {Regular, Tree adjoining, Evolutionary computation, Grammar, Genetic programming, Context free}
}

@article{miller_color_2022,
	title = {Color in motion: {Generating} 3-dimensional multispectral models to study dynamic visual signals in animals},
	volume = {10},
	issn = {2296-701X},
	shorttitle = {Color in motion},
	url = {https://www.frontiersin.org/articles/10.3389/fevo.2022.983369},
	abstract = {Analyzing color and pattern in the context of motion is a central and ongoing challenge in the quantification of animal coloration. Many animal signals are spatially and temporally variable, but traditional methods fail to capture this dynamism because they use stationary animals in fixed positions. To investigate dynamic visual displays and to understand the evolutionary forces that shape dynamic colorful signals, we require cross-disciplinary methods that combine measurements of color, pattern, 3-dimensional (3D) shape, and motion. Here, we outline a workflow for producing digital 3D models with objective color information from museum specimens with diffuse colors. The workflow combines multispectral imaging with photogrammetry to produce digital 3D models that contain calibrated ultraviolet (UV) and human-visible (VIS) color information and incorporate pattern and 3D shape. These “3D multispectral models” can subsequently be animated to incorporate both signaler and receiver movement and analyzed in silico using a variety of receiver-specific visual models. This approach—which can be flexibly integrated with other tools and methods—represents a key first step toward analyzing visual signals in motion. We describe several timely applications of this workflow and next steps for multispectral 3D photogrammetry and animation techniques.},
	urldate = {2022-11-19},
	journal = {Frontiers in Ecology and Evolution},
	author = {Miller, Audrey E. and Hogan, Benedict G. and Stoddard, Mary Caswell},
	year = {2022},
	keywords = {3d, animation, camouflage, cocish, coloration, dynamic, in silico, modeling, motion, multispectral, predator, signal, vision},
	file = {Full Text PDF:/Users/cwr/Zotero/storage/IVEHRXRR/Miller et al. - 2022 - Color in motion Generating 3-dimensional multispe.pdf:application/pdf},
    numpages = {19},
}

@article{montana_strongly_1995,
	title = {Strongly {Typed} {Genetic} {Programming}},
	volume = {3},
	url = {http://web.archive.org/web/20070814014654/http://vishnu.bbn.com/papers/stgp.pdf},
	abstract = {Genetic programming is a powerful method for automatically generating computer programs via the process of natural selection (Koza, 1992). However, in its standard form, there is no way to restrict the programs it generates to those where the functions operate on appropriate data types. In the case when the programs manipulate multiple data types and contain functions designed to operate on particular data types, this can lead to unnecessarily large search times and/or unnecessarily poor generalization performance. Strongly typed genetic programming (STGP) is an enhanced version of genetic programming which enforces data type constraints and whose use of generic functions and generic data types makes it more powerful than other approaches to type constraint enforcement. After describing its operation, we illustrate its use on problems in two domains, matrix/vector manipulation and list manipulation, which require its generality. The examples are: (1) the multi-dimensional least-squares regression problem, (2) the multi-dimensional Kalman ﬁlter, (3) the list manipulation function NTH, and (4) the list manipulation function MAPCAR.},
	number = {2},
	journal = {Evolutionary Computation},
	author = {Montana, David J.},
	year = {1995},
	keywords = {self\_organizing, evolution, algorithm, emergence, optimization, gp},
	pages = {199--230},
	annote = {See also July 1993 BBN Technical Report \#7866 of the same name – http://www.citeulike.org/user/numata/article/219660},
}


@article{murray_how_1988,
	title = {How the leopard gets its spots},
	volume = {258},
	url = {http://www.resnet.wm.edu/∼jxshix/math490/murray.doc},
	abstract = {Mammals exhibit a remarkable variety of coat patterns; the variety has elicited a comparable variety of explanations—many of them at the level of cogency that prevails in Rudyard Kipling's delightful "How the Leopard Got Its Spots." Although genes control the processes involved in coat pattern formation, the actual mechanisms that create the patterns are still not known. It would be attractive from the viewpoint of both evolutionary and developmental biology if a single mechanism were found to produce the enormous assortment of coat patterns found in nature.},
	number = {3},
	journal = {Scientific American},
	author = {Murray, James D.},
	month = mar,
	year = {1988},
	keywords = {camouflage, morphogenesis, texture\_synthesis, reaction-diffusion},
	pages = {80--87},
}

@INPROCEEDINGS{owens_camouflaging_2014,
    author={Owens, Andrew and Barnes, Connelly and Flint, Alex and Singh, Hanumant and Freeman, William},
    booktitle={2014 IEEE Conference on Computer Vision and Pattern Recognition}, 
    title={Camouflaging an Object from Many Viewpoints}, 
    year={2014},
    volume={},
    number={},
    address={Columbus, OH, USA},
    publisher = {IEEE CVPR},
    pages={2782-2789},
    doi={10.1109/CVPR.2014.350}
}

@inproceedings{pang_zoom_2022,
	address = {New Orleans, LA, USA},
	title = {Zoom {In} and {Out}: {A} {Mixed}-scale {Triplet} {Network} for {Camouflaged} {Object} {Detection}},
	isbn = {978-1-66546-946-3},
	shorttitle = {Zoom {In} and {Out}},
	url = {https://ieeexplore.ieee.org/document/9878581/},
	doi = {10.1109/CVPR52688.2022.00220},
	abstract = {The recently proposed camouflaged object detection (COD) attempts to segment objects that are visually blended into their surroundings, which is extremely complex and difficult in real-world scenarios. Apart from high intrinsic similarity between the camouflaged objects and their background, the objects are usually diverse in scale, fuzzy in appearance, and even severely occluded. To deal with these problems, we propose a mixed-scale triplet network, ZoomNet, which mimics the behavior of humans when observing vague images, i.e., zooming in and out. Specifically, our ZoomNet employs the zoom strategy to learn the discriminative mixed-scale semantics by the designed scale integration unit and hierarchical mixed-scale unit, which fully explores imperceptible clues between the candidate objects and background surroundings. Moreover, considering the uncertainty and ambiguity derived from indistinguishable textures, we construct a simple yet effective regularization constraint, uncertainty-aware loss, to promote the model to accurately produce predictions with higher confidence in candidate regions. Without bells and whistles, our proposed highly task-friendly model consistently surpasses the existing 23 state-of-the-art methods on four public datasets. Besides, the superior performance over the recent cuttingedge models on the SOD task also verifies the effectiveness and generality of our model. The code will be available at https://github.com/lartpang/ZoomNet.},
	language = {en},
	urldate = {2022-10-28},
	booktitle = {2022 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Pang, Youwei and Zhao, Xiaoqi and Xiang, Tian-Zhu and Zhang, Lihe and Lu, Huchuan},
	month = jun,
	year = {2022},
	pages = {2150--2160},
	file = {Pang et al. - 2022 - Zoom In and Out A Mixed-scale Triplet Network for.pdf:/Users/cwr/Zotero/storage/99IHVM5Z/Pang et al. - 2022 - Zoom In and Out A Mixed-scale Triplet Network for.pdf:application/pdf},
}

@article{perlin_image_1985,
	title = {An image synthesizer},
	volume = {19},
	issn = {0097-8930},
	url = {http://dx.doi.org/10.1145/325334.325247},
	doi = {10.1145/325334.325247},
	abstract = {We introduce the concept of a Pixel Stream Editor. This forms the basis for an interactive synthesizer for designing highly realistic Computer Generated Imagery. The designer works in an interactive Very High Level programming environment which provides a very fast concept/implement/view iteration cycle. Naturalistic visual complexity is built up by composition of non-linear functions, as opposed to the more conventional texture mapping or growth model algorithms. Powerful primitives are included for creating controlled stochastic effects. We introduce the concept of "solid texture" to the field of CGI.We have used this system to create very convincing representations of clouds, fire, water, stars, marble, wood, rock, soap films and crystal. The algorithms created with this paradigm are generally extremely fast, highly realistic, and asynchronously parallelizable at the pixel level.},
	number = {3},
	journal = {SIGGRAPH '85: Proceedings of the 12th annual conference on Computer graphics and interactive techniques},
	author = {Perlin, Ken},
	month = jul,
	year = {1985},
	keywords = {noise, pattern, texture\_synthesis},
	pages = {287--296},
}

@article{reynolds_iec_2011,
    author = {Reynolds, Craig},
    title = "{Interactive Evolution of Camouflage}",
    journal = {Artificial Life},
    volume = {17},
    number = {2},
    pages = {123-136},
    year = {2011},
    month = {04},
    abstract = "{This article presents an abstract computation model of the evolution of camouflage in nature. The 2D model uses evolved textures for prey, a background texture representing the environment, and a visual predator. A human observer, acting as the predator, is shown a cohort of 10 evolved textures overlaid on the background texture. The observer clicks on the five most conspicuous prey to remove (“eat”) them. These lower-fitness textures are removed from the population and replaced with newly bred textures. Biological morphogenesis is represented in this model by procedural texture synthesis. Nested expressions of generators and operators form a texture description language. Natural evolution is represented by genetic programming (GP), a variant of the genetic algorithm. GP searches the space of texture description programs for those that appear least conspicuous to the predator.}",
    issn = {1064-5462},
    doi = {10.1162/artl_a_00023},
    url = {https://doi.org/10.1162/artl\_a\_00023},
    eprint = {},
}

@article{sims_evolving_1994,
    author = {Sims, Karl},
    title = {Evolving 3d Morphology and Behavior by Competition},
    year = {1994},
    issue_date = {Summer 1994},
    publisher = {MIT Press},
    address = {Cambridge, MA, USA},
    volume = {1},
    number = {4},
    issn = {1064-5462},
    url = {https://doi.org/10.1162/artl.1994.1.4.353},
    doi = {10.1162/artl.1994.1.4.353},
    abstract = {This article describes a system for the evolution and coevolution of virtual creatures that compete in physically simulated three-dimensional worlds. Pairs of individuals enter one-on-one contests in which they contend to gain control of a common resource. The winners receive higher relative fitness scores allowing them to survive and reproduce. Realistic dynamics simulation including gravity, collisions, and friction, restricts the actions to physically plausible behaviors.The morphology of these creatures and the neural systems for controlling their muscle forces are both genetically determined, and the morphology and behavior can adapt to each other as they evolve simultaneously. The genotypes are structured as directed graphs of nodes and connections, and they can efficiently but flexibly describe instructions for the development of creatures' bodies and control systems with repeating or recursive components. When simulated evolutions are performed with populations of competing creatures, interesting and diverse strategies and counterstrategies emerge.},
    journal = {Artif. Life},
    month = {jul},
    pages = {353–372},
    numpages = {20},
    keywords = {artificial evolution, virtual creatures, coevolution, evolutionary programming, artificial life, dynamic simulation}
}

@inproceedings{sims_artificial_1991,
	address = {New York, NY, USA},
	title = {Artificial evolution for computer graphics},
	volume = {25},
	isbn = {0-89791-436-8},
	url = {http://www.genarts.com/karl/papers/siggraph91.html},
	doi = {10.1145/122718.122752},
	abstract = {This paper describes how evolutionary techniques of variation and selection can be used to create complex simulated structures, textures, and motions for use in computer graphics and animation. Interactive selection, based on visual perception of procedurally generated results, allows the user to direct simulated evolutions in preferred directions. Several examples using these methods have been implemented and are described. 3D plant structures are grown using fixed sets of genetic parameters. Images, solid textures, and animations are created using mutating symbolic lisp expressions. Genotypes consisting of symbolic expressions are presented as an attempt to surpass the limitations of fixed-length genotypes with predefined expression rules. It is proposed that artificial evolution has potential as a powerful tool for achieving flexible complexity with a minimum of user input and knowledge of details.},
	booktitle = {{SIGGRAPH} '91: {Proceedings} of the 18th annual conference on {Computer} graphics and interactive techniques},
	publisher = {ACM},
	author = {Sims, Karl},
	month = jul,
	year = {1991},
	keywords = {evolution, color, texture\_synthesis, gp, humanfitnessfunction},
	pages = {319--328},
}

@misc{stevens_games_2022,
    title={ Games: Sensory Ecology and Evolution},
    author={Stevens, Martin and others},
    year={2022},
    howpublished={\url{https://www.sensoryecology.com/games/}},
}

@techreport{sun_boundary-guided_2022,
	title = {Boundary-{Guided} {Camouflaged} {Object} {Detection}},
	url = {http://arxiv.org/abs/2207.00794},
	abstract = {Camouflaged object detection (COD), segmenting objects that are elegantly blended into their surroundings, is a valuable yet challenging task. Existing deep-learning methods often fall into the difficulty of accurately identifying the camouflaged object with complete and fine object structure. To this end, in this paper, we propose a novel boundary-guided network (BGNet) for camouflaged object detection. Our method explores valuable and extra object-related edge semantics to guide representation learning of COD, which forces the model to generate features that highlight object structure, thereby promoting camouflaged object detection of accurate boundary localization. Extensive experiments on three challenging benchmark datasets demonstrate that our BGNet significantly outperforms the existing 18 state-of-the-art methods under four widely-used evaluation metrics. Our code is publicly available at: https://github.com/thograce/BGNet.},
	number = {arXiv:2207.00794},
	urldate = {2022-07-29},
	institution = {arXiv},
	author = {Sun, Yujia and Wang, Shuo and Chen, Chenglizhao and Xiang, Tian-Zhu},
	month = jul,
	year = {2022},
	doi = {10.48550/arXiv.2207.00794},
	note = {arXiv:2207.00794 [cs] type: article},
	keywords = {camouflage, cocish, predator, prey, vision, detection, Computer Science - Computer Vision and Pattern Recognition, Object detection, breaking},
	annote = {Comment: Accepted by IJCAI2022},
	file = {arXiv Fulltext PDF:/Users/cwr/Zotero/storage/Q98WB5DY/Sun et al. - 2022 - Boundary-Guided Camouflaged Object Detection.pdf:application/pdf;arXiv.org Snapshot:/Users/cwr/Zotero/storage/VTK9VHKN/2207.html:text/html},
}

@incollection{syswerda_study_1991,
	title = {A {Study} of {Reproduction} in {Generational} and {Steady}-{State} {Genetic} {Algorithms}},
	volume = {1},
	url = {https://www.sciencedirect.com/science/article/pii/B9780080506845500094},
	abstract = {Two techniques of population control are currently used in the field of serial genetic algorithms: generational and steady state. Although they have been used somewhat interchangeably in the past, it has become apparent that the two techniques are actually quite different. In this paper, I study the behavior of each with regard to reproduction, and show that while each can be made similar with respect to the schema theorem, in practice their behavior is quite different.},
	language = {en},
	urldate = {2022-12-04},
	booktitle = {Foundations of {Genetic} {Algorithms}},
	publisher = {Elsevier},
    address = {Amsterdam},
	author = {Syswerda, Gilbert},
	editor = {Rawlins, Gregory J. E.},
	month = jan,
	year = {1991},
	doi = {10.1016/B978-0-08-050684-5.50009-4},
	keywords = {generational reproduction, population, reproduction, steady-state reproduction},
	pages = {94--101},
	file = {ScienceDirect Snapshot:/Users/cwr/Zotero/storage/P8IYJRLN/B9780080506845500094.html:text/html;Syswerda - 1991 - A Study of Reproduction in Generational and Steady.pdf:/Users/cwr/Zotero/storage/GIGTKITI/Syswerda - 1991 - A Study of Reproduction in Generational and Steady.pdf:application/pdf},
}

@article{talas_camogan_2020,
    author = {Talas, Laszlo and Fennell, John G. and Kjernsmo, Karin and Cuthill, Innes C. and Scott-Samuel, Nicholas E. and Baddeley, Roland J.},
    title = {CamoGAN: Evolving optimum camouflage with Generative Adversarial Networks},
    journal = {Methods in Ecology and Evolution},
    volume = {11},
    number = {2},
    pages = {240-247},
    keywords = {CamoGAN, camouflage, co-evolution, deep learning, generative adversarial networks, predator-prey interactions, protective colouration, signalling patterns},
    doi = {https://doi.org/10.1111/2041-210X.13334},
    abstract = {Abstract One of the most challenging issues in modelling the evolution of protective colouration is the immense number of potential combinations of colours and textures. We describe CamoGAN, a novel method to exploit Generative Adversarial Networks to simulate an evolutionary arms race between the camouflage of a synthetic prey and its predator. Patterns evolved using our methods are shown to provide progressively more effective concealment and outperform two recognized camouflage techniques, as validated by using humans as visual predators. We believe CamoGAN will be highly useful, particularly for biologists, for rapidly developing and testing optimal camouflage or signalling patterns in multiple environments.},
    year = {2020}
}

@misc{tensorflow_whitepaper_2015,
    title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
    url={https://www.tensorflow.org/},
    author={Mart\'{i}n~Abadi and others},
    year={2015},
    }

@book{thayer_concealing-coloration_1909,
	address = {New York, NY},
	title = {Concealing-coloration in the animal kingdom: an exposition of the laws of disguise through color and pattern: being a summary of {Abbott} {H}. {Thayer}'s discoveries.},
	url = {http://books.google.com/books?id=vtgKAAAAIAAJ},
	abstract = {PROTECTIVE COLORATION with its achievement of the wonderful inconspicuousness of many wild animals in their native haunts has been recognized since the earliest days of Natural History study. But the true character of this phenomenon has been ignored or misinterpreted and the phenomenon itself has been observed only in one small corner of its wide field of action. It has waited for an artist in the last years of the nineteenth century not only to recognize the basic working laws of protective coloration but to perceive that the many animals of supposed conspicuous attire are almost all colored and marked in the way most potent to conceal them...},
	publisher = {Macmillan},
	author = {Thayer, Gerald H.},
	year = {1909},
	keywords = {camouflage, history},
}

@book{todd_evolutionary_1994,
    author = {Todd, Stephen and Latham, William},
    title = {Evolutionary Art and Computers},
    year = {1994},
    isbn = {012437185X},
    publisher = {Academic Press, Inc.},
    address = {USA} 
}

@article{turing_chemical_1952,
	title = {The {Chemical} {Basis} of {Morphogenesis}},
	volume = {237},
	issn = {00804622},
	url = {http://books.google.com/books?id=x7mMr4twnloC&#38;pg=PA519&#38;sig=bdwzX6QQ2cEYaTGRUKFprw8b_0A},
	doi = {10.2307/92463},
	abstract = {It is suggested that a system of chemical substances, called morphogens, reacting together and diffusing through a tissue, is adequate to account for the main phenomena of morphogenesis. Such a system, although it may originally be quite homogeneous, may later develop a pattern or structure due to an instability of the homogeneous equilibrium, which is triggered off by random disturbances. Such reaction-diffusion systems are considered in some detail in the case of an isolated ring of cells, a mathematically convenient, though biologically unusual system. The investigation is chiefly concerned with the onset of instability. It is found that there are six essentially different forms which this may take. In the most interesting form stationary waves appear on the ring. It is suggested that this might account, for instance, for the tentacle patterns on Hydra and for whorled leaves. A system of reactions and diffusion on a sphere is also considered. Such a system appears to account for gastrulation. Another reaction system in two dimensions gives rise to patterns reminiscent of dappling. It is also suggested that stationary waves in two dimensions could account for the phenomena of phyllotaxis. The purpose of this paper is to discuss a possible mechanism by which the genes of a zygote may determine the anatomical structure of the resulting organism. The theory does not make any new hypotheses; it merely suggests that certain well-known physical laws are sufficient to account for many of the facts. The full understanding of the paper requires a good knowledge of mathematics, some biology, and some elementary chemistry. Since readers cannot be expected to be experts in all of these subjects, a number of elementary facts are explained, which can be found in text-books, but whose omission would make the paper difficult reading.},
	number = {641},
	journal = {Philosophical Transactions of the Royal Society of London. Series B, Biological Sciences},
	author = {Turing, A. M.},
	year = {1952},
	keywords = {camouflage, morphogenesis, texture\_synthesis, natureinspired, reaction-diffusion},
	pages = {37--72},
	annote = {(private-note)see Turing1952morphogenesis.pdf on laptop},
}

@inproceedings{10.1145/122718.122749,
author = {Turk, Greg},
title = {Generating Textures on Arbitrary Surfaces Using Reaction-Diffusion},
year = {1991},
isbn = {0897914368},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/122718.122749},
doi = {10.1145/122718.122749},
abstract = {This paper describes a biologically motivated method of texture synthesis called reaction-diffusion and demonstrates how these textures can be generated in a manner that directly matches the geometry of a given surface. Reaction-diffusion is a process in which two or more chemicals diffuse at unequal rates over a surface and react with one another to form stable patterns such as spots and stripes. Biologists and mathematicians have explored the patterns made by several reaction-diffusion systems. We extend the range of textures that have previously been generated by using a cascade of multiple reaction-diffusion systems in which one system lays down an initial pattern and then one or more later systems refine the pattern. Examples of patterns generated by such a cascade process include the clusters of spots on leopards known as rosettes and the web-like patterns found on giraffes. In addition, this paper introduces a method which reaction-diffusion textures are created to match the geometry of an arbitrary polyhedral surface. This is accomplished by creating a mesh over a given surface and then simulating the reaction-diffusion process directly on this mesh. This avoids the often difficult task of assigning texture coordinates to a complex surface. A mesh is generated by evenly distributing points over the model using relaxation and then determining which points are adjacent by constructing their Voronoi regions. Textures are rendered directly from the mesh by using a weighted sum of mesh values to compute surface color at a given position. Such textures can also be used as bump maps.},
booktitle = {Proceedings of the 18th Annual Conference on Computer Graphics and Interactive Techniques},
pages = {289–298},
numpages = {10},
keywords = {reaction-diffusion, texture mapping, biological models},
series = {SIGGRAPH '91}
}

@article{turk_generating_1991,
    author = {Turk, Greg},
    title = {Generating Textures on Arbitrary Surfaces Using Reaction-Diffusion},
    year = {1991},
    issue_date = {July 1991},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {25},
    number = {4},
    issn = {0097-8930},
    url = {https://doi.org/10.1145/127719.122749},
    doi = {10.1145/127719.122749},
    abstract = {This paper describes a biologically motivated method of texture synthesis called reaction-diffusion and demonstrates how these textures can be generated in a manner that directly matches the geometry of a given surface. Reaction-diffusion is a process in which two or more chemicals diffuse at unequal rates over a surface and react with one another to form stable patterns such as spots and stripes. Biologists and mathematicians have explored the patterns made by several reaction-diffusion systems. We extend the range of textures that have previously been generated by using a cascade of multiple reaction-diffusion systems in which one system lays down an initial pattern and then one or more later systems refine the pattern. Examples of patterns generated by such a cascade process include the clusters of spots on leopards known as rosettes and the web-like patterns found on giraffes. In addition, this paper introduces a method which reaction-diffusion textures are created to match the geometry of an arbitrary polyhedral surface. This is accomplished by creating a mesh over a given surface and then simulating the reaction-diffusion process directly on this mesh. This avoids the often difficult task of assigning texture coordinates to a complex surface. A mesh is generated by evenly distributing points over the model using relaxation and then determining which points are adjacent by constructing their Voronoi regions. Textures are rendered directly from the mesh by using a weighted sum of mesh values to compute surface color at a given position. Such textures can also be used as bump maps.},
    journal = {SIGGRAPH Comput. Graph.},
    month = {jul},
    pages = {289–298},
    numpages = {10},
    keywords = {reaction-diffusion, biological models, texture mapping}
    }



@book{valiant_probably_2013,
	address = {New York},
	title = {Probably {Approximately} {Correct}: {Nature}'s {Algorithms} for {Learning} and {Prospering} in a {Complex} {World}},
	isbn = {0-465-03271-0},
	url = {https://www.basicbooks.com/titles/leslie-valiant/probably-approximately-correct/9780465037902/},
	abstract = {From a leading computer scientist, a grand unifying theory that will revolutionize our understanding of how life evolves and learns, and hence what life is. How does life prosper in a complex and erratic world? While we know that nature follows patterns—such as the law of gravity—our everyday lives are beyond what known science can predict. We nevertheless muddle through even in the absence of theories of how to act. But how do we do it? In Probably Approximately Correct, computer scientist Leslie Valiant presents a masterful synthesis of learning and evolution to show how both individually and collectively we not only survive, but prosper in a world as complex as our own. The key is ” probably approximately correct” algorithms, a concept Valiant developed to explain how effective behavior can be learned. The model shows that pragmatically coping with a problem can provide a satisfactory solution in the absence of any theory of the problem. After all, finding a mate does not require a theory of mating. Valiant's theory reveals the shared computational nature of evolution and learning, and sheds light on perennial questions such as nature versus nurture and the limits of artificial intelligence. Valiant provides a new perspective on human nature as a product of evolution and adaptation. If, as human beings, we are shaped entirely by evolution before conception and learning afterwards, then all our characteristics, whether biological or psychological, will have been determined by adaptive mechanisms. Offering a powerful and elegant model that encompasses life's complexity, Probably Approximately Correct has profound implications for how we think about behavior, cognition, biological evolution, and the possibilities and limits of human and machine intelligence.},
	publisher = {Basic Books},
	author = {Valiant, Leslie},
	month = jun,
	year = {2013},
	keywords = {ai, computation, darwin, evolution, learning, machinelearning, pac, theory, turing},
}

@inproceedings{10.1145/122718.122750,
author = {Witkin, Andrew and Kass, Michael},
title = {Reaction-Diffusion Textures},
year = {1991},
isbn = {0897914368},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/122718.122750},
doi = {10.1145/122718.122750},
abstract = {We present a method for texture synthesis based on the simulation of a process of local nonlinear interaction, called reaction-diffusion, which has been proposed as a model of biological pattern formation. We extend traditional reaction-diffusion systems by allowing anisotropic and spatially non-uniform diffusion, as well as multiple competing directions of diffusion. We adapt reaction-diffusion system to the needs of computer graphics by presenting a method to synthesize patterns which compensate for the effects of non-uniform surface parameterization. Finally, we develop efficient algorithms for simulating reaction-diffusion systems and display a collection of resulting textures using standard texture- and displacement-mapping techniques.},
booktitle = {Proceedings of the 18th Annual Conference on Computer Graphics and Interactive Techniques},
pages = {299–308},
numpages = {10},
keywords = {texture synthesis, natural phenomena},
series = {SIGGRAPH '91}
}

@article{witkin_reaction_1991,
    author = {Witkin, Andrew and Kass, Michael},
    title = {Reaction-Diffusion Textures},
    year = {1991},
    issue_date = {July 1991},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {25},
    number = {4},
    issn = {0097-8930},
    url = {https://doi.org/10.1145/127719.122750},
    doi = {10.1145/127719.122750},
    abstract = {We present a method for texture synthesis based on the simulation of a process of local nonlinear interaction, called reaction-diffusion, which has been proposed as a model of biological pattern formation. We extend traditional reaction-diffusion systems by allowing anisotropic and spatially non-uniform diffusion, as well as multiple competing directions of diffusion. We adapt reaction-diffusion system to the needs of computer graphics by presenting a method to synthesize patterns which compensate for the effects of non-uniform surface parameterization. Finally, we develop efficient algorithms for simulating reaction-diffusion systems and display a collection of resulting textures using standard texture- and displacement-mapping techniques.},
    journal = {SIGGRAPH Comput. Graph.},
    month = {jul},
    pages = {299–308},
    numpages = {10},
    keywords = {texture synthesis, natural phenomena}
}

@misc{visionxiang_cod,
    author = {visionxiang},
    title = {Camouflaged/Concealed Object Detection},
    url = {https://github.com/visionxiang/awesome-camouflaged-object-detection},
    year = {2022},
    urldate = {27.10.2022},
    originalyear = {4.10.2016}
}

@misc{yin_camoformer_2022,
  doi = {10.48550/ARXIV.2212.06570},
  url = {https://arxiv.org/abs/2212.06570},
  author = {Yin, Bowen and Zhang, Xuying and Hou, Qibin and Sun, Bo-Yuan and Fan, Deng-Ping and Van Gool, Luc},
  keywords = {Computer Vision and Pattern Recognition (cs.CV), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {CamoFormer: Masked Separable Attention for Camouflaged Object Detection},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}

@article{Zhang_Yin_Nie_Zheng_2020,
    title={Deep Camouflage Images},
    author={Zhang, Qing and Yin, Gelin and Nie, Yongwei and Zheng, Wei-Shi},
    volume={34},
    url={https://ojs.aaai.org/index.php/AAAI/article/view/6981},
    DOI={10.1609/aaai.v34i07.6981},
    number={07},
    journal={Proceedings of the AAAI Conference on Artificial Intelligence},
    year={2020},
    month={Apr.},
    pages={12845-12852},
    abstractNote={&lt;p&gt;This paper addresses the problem of creating &lt;em&gt;camouflage images&lt;/em&gt;. Such images typically contain one or more hidden objects embedded into a background image, so that viewers are required to consciously focus to discover them. Previous methods basically rely on hand-crafted features and texture synthesis to create camouflage images. However, due to lack of reliable understanding of what essentially makes an object recognizable, they typically result in either complete standout or complete invisible hidden objects. Moreover, they may fail to produce seamless and natural images because of the sensitivity to appearance differences. To overcome these limitations, we present a novel neural style transfer approach that adopts the visual perception mechanism to create camouflage images, which allows us to hide objects more effectively while producing natural-looking results. In particular, we design an attention-aware camouflage loss to adaptively mask out information that make the hidden objects visually standout, and also leave subtle yet enough feature clues for viewers to perceive the hidden objects. To remove the appearance discontinuities between the hidden objects and the background, we formulate a naturalness regularization to constrain the hidden objects to maintain the manifold structure of the covered background. Extensive experiments show the advantages of our approach over existing camouflage methods and state-of-the-art neural style transfer algorithms.&lt;/p&gt;}
}

@inproceedings{Zhang2022,
    author = {Zhang, Miao and Xu, Shuang and Piao, Yongri and Shi, Dongxiang and Lin, Shusen and Lu, Huchuan},
    title = {PreyNet: Preying on Camouflaged Objects},
    year = {2022},
    isbn = {9781450392037},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA}, url = {https://doi.org/10.1145/3503161.3548178},
    doi = {10.1145/3503161.3548178},
    abstract = {Species often adopt various camouflage strategies to be seamlessly blended into the surroundings for self-protection. To figure out the concealment, predators have evolved excellent hunting skills. Exploring the intrinsic mechanisms of the predation behavior can offer more insightful glimpse into the task of camouflaged object detection (COD). In this work, we strive to seek answers for accurate COD and propose a PreyNet, which mimics the two processes of predation, namely, initial detection (sensory mechanism) and predator learning (cognitive mechanism). To exploit the sensory process, a bidirectional bridging interaction module (BBIM) is designed for selecting and aggregating initial features in an attentive manner. The predator learning process is formulated as a policy-and-calibration paradigm, with the goal of deciding on uncertain regions and encouraging targeted feature calibration. Besides, we obtain adaptive weight for multi-layer supervision during training via computing on the uncertainty estimation. Extensive experiments demonstrate that our model produces state-of-the-art results on several benchmarks. We further verify the scalability of the predator learning paradigm through applications on top-ranking salient object detection models. Our code is publicly available at urlhttps://github.com/OIPLab-DUT/PreyNet.},
    booktitle = {Proceedings of the 30th ACM International Conference on Multimedia},
    pages = {5323–5332},
    numpages = {10},
    keywords = {camouflaged object detection, sensory mechanism, predator learning},
    location = {Lisboa, Portugal},
    series = {MM '22}
}